{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-28T17:38:33.921526Z",
     "iopub.status.busy": "2022-09-28T17:38:33.921239Z",
     "iopub.status.idle": "2022-09-28T17:38:33.928239Z",
     "shell.execute_reply": "2022-09-28T17:38:33.927236Z",
     "shell.execute_reply.started": "2022-09-28T17:38:33.921496Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.230058Z",
     "iopub.status.busy": "2022-09-28T17:41:09.229264Z",
     "iopub.status.idle": "2022-09-28T17:41:09.364533Z",
     "shell.execute_reply": "2022-09-28T17:41:09.363747Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.230017Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path_dataset_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-1/train_png/*.png\")\n",
    "path_dataset_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-2/train_png/*.png\")\n",
    "path_dataset_3=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-3/train_png/*.png\")\n",
    "path_dataset_4_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-4-1/train_png/*.png\")\n",
    "\n",
    "path_dataset_4_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-4-2/train_png/*.png\")\n",
    "path_dataset_5_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-5-1-index-yok/train_png/*.png\")\n",
    "\n",
    "path_dataset_5_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-5-2/train_png/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.366878Z",
     "iopub.status.busy": "2022-09-28T17:41:09.366508Z",
     "iopub.status.idle": "2022-09-28T17:41:09.375672Z",
     "shell.execute_reply": "2022-09-28T17:41:09.374920Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.366844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths=path_dataset_1+path_dataset_2+path_dataset_3+path_dataset_4_1+path_dataset_4_2+path_dataset_5_1+path_dataset_5_2\n",
    "len(train_png_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-1/train_png\\\\026c97_0.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.809532Z",
     "iopub.status.busy": "2022-09-28T17:41:09.808921Z",
     "iopub.status.idle": "2022-09-28T17:41:09.817570Z",
     "shell.execute_reply": "2022-09-28T17:41:09.816601Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.809494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'026c97_0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths[0].split('\\\\')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:10.791904Z",
     "iopub.status.busy": "2022-09-28T17:41:10.790086Z",
     "iopub.status.idle": "2022-09-28T17:41:13.257957Z",
     "shell.execute_reply": "2022-09-28T17:41:13.257070Z",
     "shell.execute_reply.started": "2022-09-28T17:41:10.791854Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DATASET_FOLDER = \"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/\"\n",
    "\n",
    "\n",
    "path_csv = os.path.join(DATASET_FOLDER, \"train.csv\")\n",
    "df_train = pd.read_csv(path_csv)\n",
    "list_df=[]\n",
    "for i in df_train.index:\n",
    "    for ii in range(len(train_png_paths)):\n",
    "        if df_train['image_id'][i]==train_png_paths[ii].split('\\\\')[-1][:-4]:\n",
    "            list_df.append([train_png_paths[ii],df_train['label'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:13.259632Z",
     "iopub.status.busy": "2022-09-28T17:41:13.259370Z",
     "iopub.status.idle": "2022-09-28T17:41:13.285180Z",
     "shell.execute_reply": "2022-09-28T17:41:13.284409Z",
     "shell.execute_reply.started": "2022-09-28T17:41:13.259595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path label\n",
       "0    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "1    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "2    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "3    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "4    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "..                                                 ...   ...\n",
       "513  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "514  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "515  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "516  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "517  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "\n",
       "[518 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(list_df,columns=['image_path','label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:13.546774Z",
     "iopub.status.busy": "2022-09-28T17:41:13.545426Z",
     "iopub.status.idle": "2022-09-28T17:41:13.569269Z",
     "shell.execute_reply": "2022-09-28T17:41:13.568268Z",
     "shell.execute_reply.started": "2022-09-28T17:41:13.546725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           filepaths labels\n",
      "0  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "1  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "2  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "3  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "4  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    LAA\n",
      "CE     392\n",
      "LAA    126\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(518, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy=df.copy()\n",
    "Fseries = pd.Series(df_copy.image_path, name=\"filepaths\")\n",
    "\n",
    "Lseries = pd.Series(df_copy.label, name=\"labels\")\n",
    "inme_data = pd.concat([Fseries,Lseries], axis=1)\n",
    "inmer_df = pd.DataFrame(inme_data)\n",
    "print(inmer_df.head())\n",
    "print(inmer_df[\"labels\"].value_counts())\n",
    "\n",
    "#shape of datatset\n",
    "inmer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:14.613867Z",
     "iopub.status.busy": "2022-09-28T17:41:14.613541Z",
     "iopub.status.idle": "2022-09-28T17:41:14.624255Z",
     "shell.execute_reply": "2022-09-28T17:41:14.623399Z",
     "shell.execute_reply.started": "2022-09-28T17:41:14.613829Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "#tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(inmer_df, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:15.022758Z",
     "iopub.status.busy": "2022-09-28T17:41:15.022475Z",
     "iopub.status.idle": "2022-09-28T17:41:15.046977Z",
     "shell.execute_reply": "2022-09-28T17:41:15.046196Z",
     "shell.execute_reply.started": "2022-09-28T17:41:15.022728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 414 validated image filenames belonging to 2 classes.\n",
      "Found 104 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "train = image_gen.flow_from_dataframe(dataframe= train_df,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(128,128),\n",
    "\n",
    "                                      class_mode='categorical', #used for Sequential Model\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )\n",
    "test = image_gen.flow_from_dataframe(dataframe= test_df,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(128,128),\n",
    "\n",
    "                                      class_mode='categorical', #used for Sequential Model\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (1.0.0)\n",
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from efficientnet) (0.19.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2022.5.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2.8.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (9.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.7.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2.19.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\n",
      "Installing collected packages: efficientnet\n",
      "  Attempting uninstall: efficientnet\n",
      "    Found existing installation: efficientnet 1.0.0\n",
      "    Uninstalling efficientnet-1.0.0:\n",
      "      Successfully uninstalled efficientnet-1.0.0\n",
      "Successfully installed efficientnet-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "segmentation-models 1.0.1 requires efficientnet==1.0.0, but you have efficientnet 1.1.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = efn.EfficientNetB7(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "predictions = Dense(2, activation=\"sigmoid\")(x)\n",
    "model_final = Model(base_model.input, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "model_final.compile(tensorflow.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard,LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=30\n",
    "                             )\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"class_model_EfficientNetB7_2_otherisinception.h5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.7464\n",
      "Epoch 1: val_loss improved from inf to 0.68615, saving model to class_model_EfficientNetB7_2_otherisinception.h5\n",
      "414/414 [==============================] - 2895s 7s/step - loss: 0.7608 - accuracy: 0.7464 - val_loss: 0.6862 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7158 - accuracy: 0.7560\n",
      "Epoch 2: val_loss improved from 0.68615 to 0.66393, saving model to class_model_EfficientNetB7_2_otherisinception.h5\n",
      "414/414 [==============================] - 2882s 7s/step - loss: 0.7158 - accuracy: 0.7560 - val_loss: 0.6639 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.7560\n",
      "Epoch 3: val_loss did not improve from 0.66393\n",
      "414/414 [==============================] - 2840s 7s/step - loss: 0.7324 - accuracy: 0.7560 - val_loss: 0.6883 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7780 - accuracy: 0.7609\n",
      "Epoch 4: val_loss did not improve from 0.66393\n",
      "414/414 [==============================] - 2893s 7s/step - loss: 0.7780 - accuracy: 0.7609 - val_loss: 0.6883 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7144 - accuracy: 0.7609\n",
      "Epoch 5: val_loss did not improve from 0.66393\n",
      "414/414 [==============================] - 3067s 7s/step - loss: 0.7144 - accuracy: 0.7609 - val_loss: 0.7197 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7182 - accuracy: 0.7609\n",
      "Epoch 6: val_loss did not improve from 0.66393\n",
      "414/414 [==============================] - 2992s 7s/step - loss: 0.7182 - accuracy: 0.7609 - val_loss: 0.6818 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.7585\n",
      "Epoch 7: val_loss improved from 0.66393 to 0.64419, saving model to class_model_EfficientNetB7_2_otherisinception.h5\n",
      "414/414 [==============================] - 2994s 7s/step - loss: 0.7288 - accuracy: 0.7585 - val_loss: 0.6442 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7138 - accuracy: 0.7633\n",
      "Epoch 8: val_loss did not improve from 0.64419\n",
      "414/414 [==============================] - 2997s 7s/step - loss: 0.7138 - accuracy: 0.7633 - val_loss: 0.7291 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.7179 - accuracy: 0.7633\n",
      "Epoch 9: val_loss did not improve from 0.64419\n",
      "414/414 [==============================] - 2993s 7s/step - loss: 0.7179 - accuracy: 0.7633 - val_loss: 0.6627 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.7609\n",
      "Epoch 10: val_loss did not improve from 0.64419\n",
      "414/414 [==============================] - 3015s 7s/step - loss: 0.6969 - accuracy: 0.7609 - val_loss: 0.6473 - val_accuracy: 0.7404 - lr: 1.0000e-04\n",
      "Total time:  29572.18879675865 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "start = time.time()\n",
    "eff_history = model_final.fit_generator(train, epochs = 10, validation_data=test,\n",
    "                                        callbacks = [checkpointer, earlystopping, reduce_lr])\n",
    "print(\"Total time: \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.save('B7_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
