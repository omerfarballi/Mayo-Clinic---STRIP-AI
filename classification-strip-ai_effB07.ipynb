{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# İntro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-28T17:38:33.921526Z",
     "iopub.status.busy": "2022-09-28T17:38:33.921239Z",
     "iopub.status.idle": "2022-09-28T17:38:33.928239Z",
     "shell.execute_reply": "2022-09-28T17:38:33.927236Z",
     "shell.execute_reply.started": "2022-09-28T17:38:33.921496Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.230058Z",
     "iopub.status.busy": "2022-09-28T17:41:09.229264Z",
     "iopub.status.idle": "2022-09-28T17:41:09.364533Z",
     "shell.execute_reply": "2022-09-28T17:41:09.363747Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.230017Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path_dataset_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-1/train_png/*.png\")\n",
    "path_dataset_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-2/train_png/*.png\")\n",
    "path_dataset_3=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-3/train_png/*.png\")\n",
    "path_dataset_4_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-4-1/train_png/*.png\")\n",
    "\n",
    "path_dataset_4_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-4-2/train_png/*.png\")\n",
    "path_dataset_5_1=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-5-1-index-yok/train_png/*.png\")\n",
    "\n",
    "path_dataset_5_2=glob.glob(\"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-5-2/train_png/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.366878Z",
     "iopub.status.busy": "2022-09-28T17:41:09.366508Z",
     "iopub.status.idle": "2022-09-28T17:41:09.375672Z",
     "shell.execute_reply": "2022-09-28T17:41:09.374920Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.366844Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths=path_dataset_1+path_dataset_2+path_dataset_3+path_dataset_4_1+path_dataset_4_2+path_dataset_5_1+path_dataset_5_2\n",
    "len(train_png_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/dataset-1/train_png\\\\026c97_0.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:09.809532Z",
     "iopub.status.busy": "2022-09-28T17:41:09.808921Z",
     "iopub.status.idle": "2022-09-28T17:41:09.817570Z",
     "shell.execute_reply": "2022-09-28T17:41:09.816601Z",
     "shell.execute_reply.started": "2022-09-28T17:41:09.809494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'026c97_0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_png_paths[0].split('\\\\')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:10.791904Z",
     "iopub.status.busy": "2022-09-28T17:41:10.790086Z",
     "iopub.status.idle": "2022-09-28T17:41:13.257957Z",
     "shell.execute_reply": "2022-09-28T17:41:13.257070Z",
     "shell.execute_reply.started": "2022-09-28T17:41:10.791854Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DATASET_FOLDER = \"C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/\"\n",
    "\n",
    "\n",
    "path_csv = os.path.join(DATASET_FOLDER, \"train.csv\")\n",
    "df_train = pd.read_csv(path_csv)\n",
    "list_df=[]\n",
    "for i in df_train.index:\n",
    "    for ii in range(len(train_png_paths)):\n",
    "        if df_train['image_id'][i]==train_png_paths[ii].split('\\\\')[-1][:-4]:\n",
    "            list_df.append([train_png_paths[ii],df_train['label'][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:13.259632Z",
     "iopub.status.busy": "2022-09-28T17:41:13.259370Z",
     "iopub.status.idle": "2022-09-28T17:41:13.285180Z",
     "shell.execute_reply": "2022-09-28T17:41:13.284409Z",
     "shell.execute_reply.started": "2022-09-28T17:41:13.259595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...</td>\n",
       "      <td>LAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path label\n",
       "0    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "1    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "2    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "3    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "4    C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "..                                                 ...   ...\n",
       "513  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "514  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "515  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "516  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    CE\n",
       "517  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...   LAA\n",
       "\n",
       "[518 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(list_df,columns=['image_path','label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:13.546774Z",
     "iopub.status.busy": "2022-09-28T17:41:13.545426Z",
     "iopub.status.idle": "2022-09-28T17:41:13.569269Z",
     "shell.execute_reply": "2022-09-28T17:41:13.568268Z",
     "shell.execute_reply.started": "2022-09-28T17:41:13.546725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           filepaths labels\n",
      "0  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "1  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "2  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "3  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...     CE\n",
      "4  C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Da...    LAA\n",
      "CE     392\n",
      "LAA    126\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(518, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy=df.copy()\n",
    "Fseries = pd.Series(df_copy.image_path, name=\"filepaths\")\n",
    "\n",
    "Lseries = pd.Series(df_copy.label, name=\"labels\")\n",
    "inme_data = pd.concat([Fseries,Lseries], axis=1)\n",
    "inmer_df = pd.DataFrame(inme_data)\n",
    "print(inmer_df.head())\n",
    "print(inmer_df[\"labels\"].value_counts())\n",
    "\n",
    "#shape of datatset\n",
    "inmer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:14.613867Z",
     "iopub.status.busy": "2022-09-28T17:41:14.613541Z",
     "iopub.status.idle": "2022-09-28T17:41:14.624255Z",
     "shell.execute_reply": "2022-09-28T17:41:14.623399Z",
     "shell.execute_reply.started": "2022-09-28T17:41:14.613829Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "#tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(inmer_df, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:15.022758Z",
     "iopub.status.busy": "2022-09-28T17:41:15.022475Z",
     "iopub.status.idle": "2022-09-28T17:41:15.046977Z",
     "shell.execute_reply": "2022-09-28T17:41:15.046196Z",
     "shell.execute_reply.started": "2022-09-28T17:41:15.022728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 414 validated image filenames belonging to 2 classes.\n",
      "Found 104 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "train = image_gen.flow_from_dataframe(dataframe= train_df,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(128,128),\n",
    "\n",
    "                                      class_mode='categorical', #used for Sequential Model\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )\n",
    "test = image_gen.flow_from_dataframe(dataframe= test_df,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(128,128),\n",
    "\n",
    "                                      class_mode='categorical', #used for Sequential Model\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:20.957612Z",
     "iopub.status.busy": "2022-09-28T17:41:20.957033Z",
     "iopub.status.idle": "2022-09-28T17:41:22.878378Z",
     "shell.execute_reply": "2022-09-28T17:41:22.877546Z",
     "shell.execute_reply.started": "2022-09-28T17:41:20.957573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "IMG_SIZE=(256,256)\n",
    "vgg16_weight_path = 'C:/Users/omerf/OneDrive/Desktop/Mayo_clinic/Dataset/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = VGG16(\n",
    "    weights=vgg16_weight_path,\n",
    "    include_top=False, \n",
    "    input_shape=IMG_SIZE + (3,)\n",
    ")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:27.784798Z",
     "iopub.status.busy": "2022-09-28T17:41:27.784519Z",
     "iopub.status.idle": "2022-09-28T17:41:27.872589Z",
     "shell.execute_reply": "2022-09-28T17:41:27.871666Z",
     "shell.execute_reply.started": "2022-09-28T17:41:27.784766Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "#model.add(layers.Flatten())\n",
    "\n",
    "#model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=RMSprop(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-28T17:41:28.442529Z",
     "iopub.status.busy": "2022-09-28T17:41:28.441892Z",
     "iopub.status.idle": "2022-09-28T18:11:48.616090Z",
     "shell.execute_reply": "2022-09-28T18:11:48.610005Z",
     "shell.execute_reply.started": "2022-09-28T17:41:28.442492Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "start = time.time()\n",
    "History = model.fit(train, epochs=10,verbose=1)\n",
    "print(\"Total time: \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: efficientnet in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (1.0.0)\n",
      "Collecting efficientnet\n",
      "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from efficientnet) (0.19.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2022.5.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (21.3)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2.8.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (9.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.7.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (2.19.5)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\omerf\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\n",
      "Installing collected packages: efficientnet\n",
      "  Attempting uninstall: efficientnet\n",
      "    Found existing installation: efficientnet 1.0.0\n",
      "    Uninstalling efficientnet-1.0.0:\n",
      "      Successfully uninstalled efficientnet-1.0.0\n",
      "Successfully installed efficientnet-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "segmentation-models 1.0.1 requires efficientnet==1.0.0, but you have efficientnet 1.1.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = efn.EfficientNetB7(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model \n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "predictions = Dense(2, activation=\"sigmoid\")(x)\n",
    "model_final = Model(base_model.input, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "model_final.compile(tensorflow.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,TensorBoard,LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=30\n",
    "                             )\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"class_model_EfficientNetB7.h5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7688 - accuracy: 0.6600\n",
      "Epoch 1: val_loss improved from inf to 0.51288, saving model to class_model_EfficientNetB7.h5\n",
      "100/100 [==============================] - 1088s 11s/step - loss: 0.7688 - accuracy: 0.6600 - val_loss: 0.5129 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 2/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9089 - accuracy: 0.6600\n",
      "Epoch 2: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1134s 11s/step - loss: 0.9089 - accuracy: 0.6600 - val_loss: 0.6918 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 3/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.7200\n",
      "Epoch 3: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1064s 11s/step - loss: 0.7246 - accuracy: 0.7200 - val_loss: 0.6889 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 4/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7619 - accuracy: 0.7400\n",
      "Epoch 4: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1034s 10s/step - loss: 0.7619 - accuracy: 0.7400 - val_loss: 0.6743 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 5/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6572 - accuracy: 0.7400\n",
      "Epoch 5: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1050s 11s/step - loss: 0.6572 - accuracy: 0.7400 - val_loss: 0.5297 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 6/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.7100\n",
      "Epoch 6: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1077s 11s/step - loss: 0.6898 - accuracy: 0.7100 - val_loss: 0.6264 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 7/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7104 - accuracy: 0.7300\n",
      "Epoch 7: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1053s 11s/step - loss: 0.7104 - accuracy: 0.7300 - val_loss: 0.5576 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 8/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7608 - accuracy: 0.7600\n",
      "Epoch 8: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1065s 11s/step - loss: 0.7608 - accuracy: 0.7600 - val_loss: 0.6753 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 9/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.7600\n",
      "Epoch 9: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1114s 11s/step - loss: 0.5943 - accuracy: 0.7600 - val_loss: 0.5434 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 10/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6600\n",
      "Epoch 10: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1087s 11s/step - loss: 0.9713 - accuracy: 0.6600 - val_loss: 0.6824 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 11/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7013 - accuracy: 0.7000\n",
      "Epoch 11: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "100/100 [==============================] - 1083s 11s/step - loss: 0.7013 - accuracy: 0.7000 - val_loss: 0.6823 - val_accuracy: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 12/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.7200\n",
      "Epoch 12: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1122s 11s/step - loss: 0.6946 - accuracy: 0.7200 - val_loss: 0.6826 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 13/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6628 - accuracy: 0.7500\n",
      "Epoch 13: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1030s 10s/step - loss: 0.6628 - accuracy: 0.7500 - val_loss: 0.6752 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 14/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.7700\n",
      "Epoch 14: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1100s 11s/step - loss: 0.6600 - accuracy: 0.7700 - val_loss: 0.6700 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 15/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.8100\n",
      "Epoch 15: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1056s 11s/step - loss: 0.7331 - accuracy: 0.8100 - val_loss: 0.6644 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 16/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6350 - accuracy: 0.8600\n",
      "Epoch 16: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1061s 11s/step - loss: 0.6350 - accuracy: 0.8600 - val_loss: 0.6166 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 17/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.8000\n",
      "Epoch 17: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1056s 11s/step - loss: 0.6223 - accuracy: 0.8000 - val_loss: 0.6080 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 18/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.7300\n",
      "Epoch 18: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1070s 11s/step - loss: 0.7212 - accuracy: 0.7300 - val_loss: 0.6343 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 19/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.8100\n",
      "Epoch 19: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1023s 10s/step - loss: 0.6614 - accuracy: 0.8100 - val_loss: 0.6238 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 20/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6924 - accuracy: 0.7700\n",
      "Epoch 20: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1078s 11s/step - loss: 0.6924 - accuracy: 0.7700 - val_loss: 0.6206 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 21/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6759 - accuracy: 0.7300\n",
      "Epoch 21: val_loss did not improve from 0.51288\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "100/100 [==============================] - 1075s 11s/step - loss: 0.6759 - accuracy: 0.7300 - val_loss: 0.5987 - val_accuracy: 0.8077 - lr: 2.0000e-05\n",
      "Epoch 22/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6248 - accuracy: 0.7600\n",
      "Epoch 22: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1081s 11s/step - loss: 0.6248 - accuracy: 0.7600 - val_loss: 0.5952 - val_accuracy: 0.8077 - lr: 4.0000e-06\n",
      "Epoch 23/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7060 - accuracy: 0.7500\n",
      "Epoch 23: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1066s 11s/step - loss: 0.7060 - accuracy: 0.7500 - val_loss: 0.5971 - val_accuracy: 0.8077 - lr: 4.0000e-06\n",
      "Epoch 24/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.7232 - accuracy: 0.7900\n",
      "Epoch 24: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1059s 11s/step - loss: 0.7232 - accuracy: 0.7900 - val_loss: 0.5924 - val_accuracy: 0.8077 - lr: 4.0000e-06\n",
      "Epoch 25/25\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.8100\n",
      "Epoch 25: val_loss did not improve from 0.51288\n",
      "100/100 [==============================] - 1078s 11s/step - loss: 0.5738 - accuracy: 0.8100 - val_loss: 0.5802 - val_accuracy: 0.8077 - lr: 4.0000e-06\n",
      "Total time:  26809.54060459137 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "start = time.time()\n",
    "eff_history = model_final.fit_generator(train, epochs = 25, steps_per_epoch=100,validation_data=test,\n",
    "                                        callbacks = [checkpointer, earlystopping, reduce_lr])\n",
    "print(\"Total time: \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
